{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97fdde3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     83\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThese groups are missing in amce_all_groups.csv: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_groups\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound groups: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(group_lookup.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m     )\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load XLSX data and create numeric unique IDs\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# If your data is not in the first sheet, change sheet_name (e.g., sheet_name=\"Sheet2\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m X = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m required_cols = \u001b[38;5;28mlist\u001b[39m(COL_TO_ATTRIBUTE.keys())\n\u001b[32m     94\u001b[39m missing_data_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X.columns]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guram\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:481\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    480\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    490\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guram\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1604\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1601\u001b[39m         ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1604\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1608\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1609\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1611\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guram\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1452\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minspect_excel_format\u001b[39m(\n\u001b[32m   1418\u001b[39m     content_or_path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   1419\u001b[39m     storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1420\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1421\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1422\u001b[39m \u001b[33;03m    Inspect the path or content of an excel file and get its format.\u001b[39;00m\n\u001b[32m   1423\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1450\u001b[39m \u001b[33;03m        If resulting stream does not have an XLS signature and is not a valid zipfile.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1452\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1454\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1455\u001b[39m         stream = handle.handle\n\u001b[32m   1456\u001b[39m         stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guram\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:935\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    926\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    927\u001b[39m             handle,\n\u001b[32m    928\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    931\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    932\u001b[39m         )\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m     handles.append(handle)\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'data.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# Files (must be in the same directory as this script)\n",
    "# ============================================================\n",
    "AMCE_PATH = \"amce_all_groups.csv\"\n",
    "DATA_PATH = \"data.xlsx\"   # <-- your data is XLSX\n",
    "\n",
    "# ============================================================\n",
    "# Settings\n",
    "# ============================================================\n",
    "ID_COL = \"obs_id\"  # numeric unique IDs: 1..N\n",
    "\n",
    "# Map your dataset column names -> AMCE \"Attribute\" names\n",
    "COL_TO_ATTRIBUTE = {\n",
    "    \"ArrivalYear\": \"Arrival\",\n",
    "    \"City\": \"City\",\n",
    "    \"AdultEdu\": \"Education\",\n",
    "    \"HouseholdComp\": \"Demographics\",\n",
    "    \"Disability\": \"Disability\",\n",
    "    \"MedicalCond\": \"Medical\",\n",
    "    \"HH_Assets\": \"Assets\",\n",
    "    \"DebtSituation\": \"Debt\",\n",
    "    \"Coping\": \"Coping\",\n",
    "    \"AssistanceHistory\": \"Previous Assistance\",\n",
    "}\n",
    "\n",
    "GROUPS = [\"Beneficiary\", \"Model\", \"Field\", \"Central\"]\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def normalize_level(x) -> str:\n",
    "    \"\"\"\n",
    "    Convert values to a canonical string that matches AMCE 'Level' better.\n",
    "    - trims whitespace\n",
    "    - converts nan/None to \"\"\n",
    "    - converts floats that are actually ints (2016.0 -> \"2016\")\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    if s.lower() in {\"nan\", \"none\", \"\"}:\n",
    "        return \"\"\n",
    "    # Fix common numeric formatting: \"2016.0\" -> \"2016\"\n",
    "    try:\n",
    "        f = float(s)\n",
    "        if f.is_integer():\n",
    "            return str(int(f))\n",
    "        return s\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "# ============================================================\n",
    "# Load AMCEs and build lookup per group\n",
    "# ============================================================\n",
    "amce = pd.read_csv(AMCE_PATH)\n",
    "\n",
    "needed_cols = {\"Group\", \"Attribute\", \"Level\", \"Estimate\"}\n",
    "missing_amce_cols = sorted(list(needed_cols - set(amce.columns)))\n",
    "if missing_amce_cols:\n",
    "    raise ValueError(\n",
    "        f\"amce_all_groups.csv is missing columns: {missing_amce_cols}. \"\n",
    "        f\"Found columns: {list(amce.columns)}\"\n",
    "    )\n",
    "\n",
    "amce = amce[[\"Group\", \"Attribute\", \"Level\", \"Estimate\"]].copy()\n",
    "amce[\"Group\"] = amce[\"Group\"].astype(str).str.strip()\n",
    "amce[\"Attribute\"] = amce[\"Attribute\"].astype(str).str.strip()\n",
    "amce[\"Level\"] = amce[\"Level\"].apply(normalize_level)\n",
    "\n",
    "group_lookup = {}\n",
    "for g, gdf in amce.groupby(\"Group\", sort=False):\n",
    "    group_lookup[g] = {\n",
    "        (row.Attribute, row.Level): float(row.Estimate)\n",
    "        for row in gdf.itertuples(index=False)\n",
    "    }\n",
    "\n",
    "missing_groups = [g for g in GROUPS if g not in group_lookup]\n",
    "if missing_groups:\n",
    "    raise ValueError(\n",
    "        f\"These groups are missing in amce_all_groups.csv: {missing_groups}. \"\n",
    "        f\"Found groups: {sorted(group_lookup.keys())}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Load XLSX data and create numeric unique IDs\n",
    "# ============================================================\n",
    "# If your data is not in the first sheet, change sheet_name (e.g., sheet_name=\"Sheet2\")\n",
    "X = pd.read_excel(DATA_PATH, sheet_name=0)\n",
    "\n",
    "required_cols = list(COL_TO_ATTRIBUTE.keys())\n",
    "missing_data_cols = [c for c in required_cols if c not in X.columns]\n",
    "if missing_data_cols:\n",
    "    raise ValueError(\n",
    "        f\"data.xlsx is missing columns: {missing_data_cols}\\n\"\n",
    "        f\"Found columns: {list(X.columns)}\"\n",
    "    )\n",
    "\n",
    "X = X.copy()\n",
    "X[ID_COL] = np.arange(1, len(X) + 1, dtype=int)\n",
    "\n",
    "# Normalize data levels to match AMCE levels\n",
    "X_norm = X.copy()\n",
    "for c in required_cols:\n",
    "    X_norm[c] = X_norm[c].apply(normalize_level)\n",
    "\n",
    "# ============================================================\n",
    "# Scoring\n",
    "# ============================================================\n",
    "def score_observations_for_group(Xn: pd.DataFrame, lookup: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Score each row by summing AMCE estimates for realized (Attribute, Level).\n",
    "    If (Attribute, Level) isn't in AMCE => treated as control => +0.\n",
    "    \"\"\"\n",
    "    scores = np.zeros(len(Xn), dtype=float)\n",
    "\n",
    "    for col, attr in COL_TO_ATTRIBUTE.items():\n",
    "        levels = Xn[col].to_numpy(dtype=str)\n",
    "        add = np.fromiter(\n",
    "            (lookup.get((attr, lvl), 0.0) for lvl in levels),\n",
    "            dtype=float,\n",
    "            count=len(levels),\n",
    "        )\n",
    "        scores += add\n",
    "\n",
    "    return pd.Series(scores, index=Xn.index, name=\"score\")\n",
    "\n",
    "# ============================================================\n",
    "# Compute scores + rankings for each group\n",
    "# ============================================================\n",
    "results = {}\n",
    "\n",
    "for g in GROUPS:\n",
    "    lookup = group_lookup[g]\n",
    "    scores = score_observations_for_group(X_norm, lookup)\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        ID_COL: X_norm[ID_COL].values,\n",
    "        \"score\": scores.values\n",
    "    })\n",
    "\n",
    "    ranked = tmp.sort_values([\"score\", ID_COL], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
    "    ranked[\"rank\"] = np.arange(1, len(ranked) + 1, dtype=int)\n",
    "\n",
    "    results[g] = {\n",
    "        \"scores_table\": tmp,                         # obs_id + score (original order)\n",
    "        \"ranking_vector\": ranked[ID_COL].to_list(),  # ordered vector of obs_id\n",
    "        \"ranking_table\": ranked,                     # obs_id + score + rank (sorted)\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Outputs\n",
    "# ============================================================\n",
    "# 1) One CSV per group: obs_id, score, rank (sorted)\n",
    "for g in GROUPS:\n",
    "    results[g][\"ranking_table\"].to_csv(f\"ranking_{g.lower()}.csv\", index=False)\n",
    "\n",
    "# 2) One wide CSV: obs_id + all group scores (unsorted)\n",
    "scores_wide = pd.DataFrame({ID_COL: X_norm[ID_COL].values})\n",
    "for g in GROUPS:\n",
    "    scores_wide[f\"score_{g.lower()}\"] = results[g][\"scores_table\"][\"score\"].values\n",
    "scores_wide.to_csv(\"scores_all_groups.csv\", index=False)\n",
    "\n",
    "# 3) Convenience: print top-10 IDs per group\n",
    "for g in GROUPS:\n",
    "    print(f\"Top 10 obs_id ({g}): {results[g]['ranking_vector'][:10]}\")\n",
    "\n",
    "print(\"\\nWrote files:\")\n",
    "for g in GROUPS:\n",
    "    print(f\" - ranking_{g.lower()}.csv\")\n",
    "print(\" - scores_all_groups.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
