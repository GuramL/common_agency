{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# Files (must be in the same directory as this script)\n",
    "# ============================================================\n",
    "AMCE_PATH = \"amce_all_groups.csv\"\n",
    "DATA_PATH = \"data.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# Settings\n",
    "# ============================================================\n",
    "# Rank: highest score = rank 1 (descending)\n",
    "# Generate numeric unique IDs: 1..N\n",
    "ID_COL = \"obs_id\"\n",
    "\n",
    "# Map your dataset column names -> AMCE \"Attribute\" names\n",
    "COL_TO_ATTRIBUTE = {\n",
    "    \"ArrivalYear\": \"Arrival\",\n",
    "    \"City\": \"City\",\n",
    "    \"AdultEdu\": \"Education\",\n",
    "    \"HouseholdComp\": \"Demographics\",\n",
    "    \"Disability\": \"Disability\",\n",
    "    \"MedicalCond\": \"Medical\",\n",
    "    \"HH_Assets\": \"Assets\",\n",
    "    \"DebtSituation\": \"Debt\",\n",
    "    \"Coping\": \"Coping\",\n",
    "    \"AssistanceHistory\": \"Previous Assistance\",\n",
    "}\n",
    "\n",
    "# Groups to compute\n",
    "GROUPS = [\"Beneficiary\", \"Model\", \"Field\", \"Central\"]\n",
    "\n",
    "# ============================================================\n",
    "# Load AMCEs and build lookup per group\n",
    "# ============================================================\n",
    "amce = pd.read_csv(AMCE_PATH)\n",
    "\n",
    "needed_cols = {\"Group\", \"Attribute\", \"Level\", \"Estimate\"}\n",
    "missing_amce_cols = sorted(list(needed_cols - set(amce.columns)))\n",
    "if missing_amce_cols:\n",
    "    raise ValueError(\n",
    "        f\"amce_all_groups.csv is missing columns: {missing_amce_cols}. \"\n",
    "        f\"Found columns: {list(amce.columns)}\"\n",
    "    )\n",
    "\n",
    "amce = amce[[\"Group\", \"Attribute\", \"Level\", \"Estimate\"]].copy()\n",
    "\n",
    "# Normalize strings for robust matching (years, whitespace, etc.)\n",
    "amce[\"Group\"] = amce[\"Group\"].astype(str).str.strip()\n",
    "amce[\"Attribute\"] = amce[\"Attribute\"].astype(str).str.strip()\n",
    "amce[\"Level\"] = amce[\"Level\"].astype(str).str.strip()\n",
    "\n",
    "# Build: group -> {(attribute, level): estimate}\n",
    "group_lookup = {}\n",
    "for g, gdf in amce.groupby(\"Group\", sort=False):\n",
    "    d = {(row.Attribute, row.Level): float(row.Estimate) for row in gdf.itertuples(index=False)}\n",
    "    group_lookup[g] = d\n",
    "\n",
    "missing_groups = [g for g in GROUPS if g not in group_lookup]\n",
    "if missing_groups:\n",
    "    raise ValueError(\n",
    "        f\"These groups are missing in amce_all_groups.csv: {missing_groups}. \"\n",
    "        f\"Found groups: {sorted(group_lookup.keys())}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Load data (5000 observations) and create unique IDs\n",
    "# ============================================================\n",
    "X = pd.read_csv(DATA_PATH)\n",
    "\n",
    "required_cols = list(COL_TO_ATTRIBUTE.keys())\n",
    "missing_data_cols = [c for c in required_cols if c not in X.columns]\n",
    "if missing_data_cols:\n",
    "    raise ValueError(\n",
    "        f\"data.csv is missing columns: {missing_data_cols}\\n\"\n",
    "        f\"Found columns: {list(X.columns)}\"\n",
    "    )\n",
    "\n",
    "# Generate numeric unique IDs: 1..N\n",
    "X = X.copy()\n",
    "X[ID_COL] = np.arange(1, len(X) + 1, dtype=int)\n",
    "\n",
    "# Normalize values to strings for matching vs AMCE \"Level\"\n",
    "X_norm = X.copy()\n",
    "for c in required_cols:\n",
    "    X_norm[c] = X_norm[c].astype(str).str.strip()\n",
    "    # Treat missing-like strings as empty => control => +0\n",
    "    X_norm.loc[X_norm[c].isin([\"nan\", \"NaN\", \"None\", \"\"]), c] = \"\"\n",
    "\n",
    "# ============================================================\n",
    "# Scoring\n",
    "# ============================================================\n",
    "def score_observations_for_group(Xn: pd.DataFrame, lookup: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Score each row by summing AMCE estimates for realized (Attribute, Level).\n",
    "    If (Attribute, Level) isn't in AMCE => treated as control => +0.\n",
    "    \"\"\"\n",
    "    scores = np.zeros(len(Xn), dtype=float)\n",
    "\n",
    "    for col, attr in COL_TO_ATTRIBUTE.items():\n",
    "        levels = Xn[col].to_numpy(dtype=str)\n",
    "        add = np.fromiter(\n",
    "            (lookup.get((attr, lvl), 0.0) for lvl in levels),\n",
    "            dtype=float,\n",
    "            count=len(levels),\n",
    "        )\n",
    "        scores += add\n",
    "\n",
    "    return pd.Series(scores, index=Xn.index, name=\"score\")\n",
    "\n",
    "# ============================================================\n",
    "# Compute scores + rankings for each group\n",
    "# ============================================================\n",
    "results = {}\n",
    "\n",
    "for g in GROUPS:\n",
    "    lookup = group_lookup[g]\n",
    "    scores = score_observations_for_group(X_norm, lookup)\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        ID_COL: X_norm[ID_COL].values,\n",
    "        \"score\": scores.values\n",
    "    })\n",
    "\n",
    "    # Rank: highest score first; stable tie-break by obs_id ascending\n",
    "    ranked = tmp.sort_values([\"score\", ID_COL], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # Add explicit rank column (1 = best)\n",
    "    ranked[\"rank\"] = np.arange(1, len(ranked) + 1, dtype=int)\n",
    "\n",
    "    results[g] = {\n",
    "        \"scores_table\": tmp,                  # obs_id + score (original order)\n",
    "        \"ranking_vector\": ranked[ID_COL].to_list(),  # ordered vector of obs_id\n",
    "        \"ranking_table\": ranked,              # obs_id + score + rank (sorted)\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Outputs\n",
    "# ============================================================\n",
    "# 1) One CSV per group: obs_id, score, rank (sorted by rank)\n",
    "for g in GROUPS:\n",
    "    results[g][\"ranking_table\"].to_csv(f\"ranking_{g.lower()}.csv\", index=False)\n",
    "\n",
    "# 2) One wide CSV: obs_id + all group scores (unsorted)\n",
    "scores_wide = pd.DataFrame({ID_COL: X_norm[ID_COL].values})\n",
    "for g in GROUPS:\n",
    "    scores_wide[f\"score_{g.lower()}\"] = results[g][\"scores_table\"][\"score\"].values\n",
    "\n",
    "scores_wide.to_csv(\"scores_all_groups.csv\", index=False)\n",
    "\n",
    "# 3) Convenience: print top-10 IDs per group\n",
    "for g in GROUPS:\n",
    "    print(f\"Top 10 obs_id ({g}): {results[g]['ranking_vector'][:10]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
