{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97fdde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 obs_id (Beneficiary): [1306, 1551, 2046, 432, 1357, 425, 239, 747, 794, 1950]\n",
      "Top 10 obs_id (Model): [6, 1674, 55, 1668, 1743, 34, 1780, 1781, 17, 98]\n",
      "Top 10 obs_id (Field): [2046, 2058, 239, 367, 747, 398, 388, 2008, 726, 214]\n",
      "Top 10 obs_id (Central): [730, 367, 731, 187, 2391, 1913, 415, 248, 1909, 717]\n",
      "\n",
      "Wrote files:\n",
      " - ranking_beneficiary.csv\n",
      " - ranking_model.csv\n",
      " - ranking_field.csv\n",
      " - ranking_central.csv\n",
      " - scores_all_groups.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# Files (must be in the same directory as this script)\n",
    "# ============================================================\n",
    "AMCE_PATH = \"amce_all_groups.csv\"\n",
    "DATA_PATH = \"data.xlsx\"   # <-- your data is XLSX\n",
    "\n",
    "# ============================================================\n",
    "# Settings\n",
    "# ============================================================\n",
    "ID_COL = \"obs_id\"  # numeric unique IDs: 1..N\n",
    "\n",
    "# Map your dataset column names -> AMCE \"Attribute\" names\n",
    "COL_TO_ATTRIBUTE = {\n",
    "    \"ArrivalYear\": \"Arrival\",\n",
    "    \"City\": \"City\",\n",
    "    \"AdultEdu\": \"Education\",\n",
    "    \"HouseholdComp\": \"Demographics\",\n",
    "    \"Disability\": \"Disability\",\n",
    "    \"MedicalCond\": \"Medical\",\n",
    "    \"HH_Assets\": \"Assets\",\n",
    "    \"DebtSituation\": \"Debt\",\n",
    "    \"Coping\": \"Coping\",\n",
    "    \"AssistanceHistory\": \"Previous Assistance\",\n",
    "}\n",
    "\n",
    "GROUPS = [\"Beneficiary\", \"Model\", \"Field\", \"Central\"]\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def normalize_level(x) -> str:\n",
    "    \"\"\"\n",
    "    Convert values to a canonical string that matches AMCE 'Level' better.\n",
    "    - trims whitespace\n",
    "    - converts nan/None to \"\"\n",
    "    - converts floats that are actually ints (2016.0 -> \"2016\")\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    if s.lower() in {\"nan\", \"none\", \"\"}:\n",
    "        return \"\"\n",
    "    # Fix common numeric formatting: \"2016.0\" -> \"2016\"\n",
    "    try:\n",
    "        f = float(s)\n",
    "        if f.is_integer():\n",
    "            return str(int(f))\n",
    "        return s\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "# ============================================================\n",
    "# Load AMCEs and build lookup per group\n",
    "# ============================================================\n",
    "amce = pd.read_csv(AMCE_PATH)\n",
    "\n",
    "needed_cols = {\"Group\", \"Attribute\", \"Level\", \"Estimate\"}\n",
    "missing_amce_cols = sorted(list(needed_cols - set(amce.columns)))\n",
    "if missing_amce_cols:\n",
    "    raise ValueError(\n",
    "        f\"amce_all_groups.csv is missing columns: {missing_amce_cols}. \"\n",
    "        f\"Found columns: {list(amce.columns)}\"\n",
    "    )\n",
    "\n",
    "amce = amce[[\"Group\", \"Attribute\", \"Level\", \"Estimate\"]].copy()\n",
    "amce[\"Group\"] = amce[\"Group\"].astype(str).str.strip()\n",
    "amce[\"Attribute\"] = amce[\"Attribute\"].astype(str).str.strip()\n",
    "amce[\"Level\"] = amce[\"Level\"].apply(normalize_level)\n",
    "\n",
    "group_lookup = {}\n",
    "for g, gdf in amce.groupby(\"Group\", sort=False):\n",
    "    group_lookup[g] = {\n",
    "        (row.Attribute, row.Level): float(row.Estimate)\n",
    "        for row in gdf.itertuples(index=False)\n",
    "    }\n",
    "\n",
    "missing_groups = [g for g in GROUPS if g not in group_lookup]\n",
    "if missing_groups:\n",
    "    raise ValueError(\n",
    "        f\"These groups are missing in amce_all_groups.csv: {missing_groups}. \"\n",
    "        f\"Found groups: {sorted(group_lookup.keys())}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Load XLSX data and create numeric unique IDs\n",
    "# ============================================================\n",
    "# If your data is not in the first sheet, change sheet_name (e.g., sheet_name=\"Sheet2\")\n",
    "X = pd.read_excel(DATA_PATH, sheet_name=0)\n",
    "\n",
    "required_cols = list(COL_TO_ATTRIBUTE.keys())\n",
    "missing_data_cols = [c for c in required_cols if c not in X.columns]\n",
    "if missing_data_cols:\n",
    "    raise ValueError(\n",
    "        f\"data.xlsx is missing columns: {missing_data_cols}\\n\"\n",
    "        f\"Found columns: {list(X.columns)}\"\n",
    "    )\n",
    "\n",
    "X = X.copy()\n",
    "X[ID_COL] = np.arange(1, len(X) + 1, dtype=int)\n",
    "\n",
    "# Normalize data levels to match AMCE levels\n",
    "X_norm = X.copy()\n",
    "for c in required_cols:\n",
    "    X_norm[c] = X_norm[c].apply(normalize_level)\n",
    "\n",
    "# ============================================================\n",
    "# Scoring\n",
    "# ============================================================\n",
    "def score_observations_for_group(Xn: pd.DataFrame, lookup: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Score each row by summing AMCE estimates for realized (Attribute, Level).\n",
    "    If (Attribute, Level) isn't in AMCE => treated as control => +0.\n",
    "    \"\"\"\n",
    "    scores = np.zeros(len(Xn), dtype=float)\n",
    "\n",
    "    for col, attr in COL_TO_ATTRIBUTE.items():\n",
    "        levels = Xn[col].to_numpy(dtype=str)\n",
    "        add = np.fromiter(\n",
    "            (lookup.get((attr, lvl), 0.0) for lvl in levels),\n",
    "            dtype=float,\n",
    "            count=len(levels),\n",
    "        )\n",
    "        scores += add\n",
    "\n",
    "    return pd.Series(scores, index=Xn.index, name=\"score\")\n",
    "\n",
    "# ============================================================\n",
    "# Compute scores + rankings for each group\n",
    "# ============================================================\n",
    "results = {}\n",
    "\n",
    "for g in GROUPS:\n",
    "    lookup = group_lookup[g]\n",
    "    scores = score_observations_for_group(X_norm, lookup)\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        ID_COL: X_norm[ID_COL].values,\n",
    "        \"score\": scores.values\n",
    "    })\n",
    "\n",
    "    ranked = tmp.sort_values([\"score\", ID_COL], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
    "    ranked[\"rank\"] = np.arange(1, len(ranked) + 1, dtype=int)\n",
    "\n",
    "    results[g] = {\n",
    "        \"scores_table\": tmp,                         # obs_id + score (original order)\n",
    "        \"ranking_vector\": ranked[ID_COL].to_list(),  # ordered vector of obs_id\n",
    "        \"ranking_table\": ranked,                     # obs_id + score + rank (sorted)\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Outputs\n",
    "# ============================================================\n",
    "# 1) One CSV per group: obs_id, score, rank (sorted)\n",
    "for g in GROUPS:\n",
    "    results[g][\"ranking_table\"].to_csv(f\"ranking_{g.lower()}.csv\", index=False)\n",
    "\n",
    "# 2) One wide CSV: obs_id + all group scores (unsorted)\n",
    "scores_wide = pd.DataFrame({ID_COL: X_norm[ID_COL].values})\n",
    "for g in GROUPS:\n",
    "    scores_wide[f\"score_{g.lower()}\"] = results[g][\"scores_table\"][\"score\"].values\n",
    "scores_wide.to_csv(\"scores_all_groups.csv\", index=False)\n",
    "\n",
    "# 3) Convenience: print top-10 IDs per group\n",
    "for g in GROUPS:\n",
    "    print(f\"Top 10 obs_id ({g}): {results[g]['ranking_vector'][:10]}\")\n",
    "\n",
    "print(\"\\nWrote files:\")\n",
    "for g in GROUPS:\n",
    "    print(f\" - ranking_{g.lower()}.csv\")\n",
    "print(\" - scores_all_groups.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7953c14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>score_beneficiary</th>\n",
       "      <th>score_model</th>\n",
       "      <th>score_field</th>\n",
       "      <th>score_central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.387121</td>\n",
       "      <td>-0.112952</td>\n",
       "      <td>0.157915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_id  score_beneficiary  score_model  score_field  score_central\n",
       "10      11            0.06545     0.387121    -0.112952       0.157915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_wide.loc[scores_wide[ID_COL] == 11, [ID_COL, \"score_beneficiary\", \"score_model\", \"score_field\", \"score_central\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
